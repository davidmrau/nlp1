{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do required imports\n",
    "import difflib\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(2834)\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib as matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = torch.load('model.pt', map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dictionary word --> id \n",
    "dictionary = pickle.load(open('dict', 'rb'))\n",
    "\n",
    "# set the maximum sequence length\n",
    "max_seq_len = 50\n",
    "\n",
    "# function to transform sentence into word id's and put them in a pytorch Variable\n",
    "# NB Assumes the sentence is already tokenised!\n",
    "def tokenise(sentence, dictionary):\n",
    "    words = sentence.split(' ')\n",
    "    l = len(words)\n",
    "    assert l <= max_seq_len, \"sentence too long\"\n",
    "    token = 0\n",
    "    ids = torch.LongTensor(l)\n",
    "\n",
    "    for word in words:\n",
    "        try:\n",
    "            ids[token] = dictionary.word2idx[word]\n",
    "        except KeyError:\n",
    "            print( word)\n",
    "            raw_input()\n",
    "            ids[token] = dictionary.word2idx['<unk>']\n",
    "        token += 1\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pytorch softmax function\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "def evaluate(model, dictionary, sentence, check_words):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    \n",
    "    # number of tokens (= output size)\n",
    "    ntokens = len(dictionary)\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    # tokenise the sentence, put in torch Variable\n",
    "    test_data = tokenise(sentence, dictionary)\n",
    "    input_data = Variable(test_data, volatile=True)\n",
    "\n",
    "    # run the model, compute probabilities by applying softmax\n",
    "    output, hidden = model(input_data, hidden)\n",
    "    output_flat = output.view(-1, ntokens)\n",
    "    logits = output[-1, :]\n",
    "    sm = softmax(logits).view(ntokens)\n",
    "    \n",
    "    # get probabilities of certain words by looking up their\n",
    "    # indices and print them\n",
    "    def get_prob(word):\n",
    "        return sm[dictionary.word2idx[word]].data[0]\n",
    "\n",
    "    #print (sentence, '\\n')\n",
    "    #print ('\\n'.join(\n",
    "    #        ['%s: %f' % (word, get_prob(word)) for word in check_words]\n",
    "    #        ) )\n",
    "    return  [{word : get_prob(word)} for word in check_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose sentence prefixes with frequent words.\n",
    "# The sentence prefixes are intended to test intervening nouns.\n",
    "\n",
    "\n",
    "NN = ['company', 'year', 'market', 'share', 'stock', 'system', 'president', 'business', \n",
    "      'quarter', 'government', 'time', 'week', 'price', 'group', 'interest',\n",
    "      'industry', 'unit','month', 'rate', 'investment', 'state', 'producer', 'income', \n",
    "      'program', 'bank', 'part', 'plan', 'sale', 'issue', 'tax', 'way', 'loss', 'executive', 'day', 'bid', 'data', 'line','hour', 'plant', 'concern']\n",
    "\n",
    "NNS = ['companies', 'years', 'markets', 'shares', 'stocks', 'systems', 'presidents', \n",
    "       'businesses', 'quarters', 'governments', 'times', 'weeks', 'prices', 'groups', 'interests', 'industries', \n",
    "       'units', 'months', 'rates', 'investments', 'states', 'producers', 'incomes', 'programs', 'banks', 'parts', 'plans', \n",
    "      'sales', 'issues', 'taxes', 'ways', 'losses', 'executives', 'days', 'bids', 'data', 'lines', 'hours', 'plants', 'concerns',]\n",
    "\n",
    "VBP = ['are', 'have', 'do', 'say', 'think', 'want', 'expect', 'include', 'ask', \n",
    "       'make', 'need', 'know', 'see', 'get', 'seem', 'remain', 'continue', 'show', 'buy', \n",
    "       'feel', 'go', 'sell', 'take', 'use', 'plan', 'look', 'tend', 'hope', 'argue', 'give',\n",
    "       'pay', 'appear', 'suggest', 'fear', 'find', 'come', 'offer', 'contend', 'agree', 'provide']\n",
    "\n",
    "VBZ = ['is', 'has', 'does', 'says', 'thinks', 'wants', 'expects', 'includes', 'asks', 'makes',\n",
    "      'needs', 'knows', 'sees', 'gets', 'seems', 'remains', 'continues', 'shows', 'buys', 'feels', 'goes', 'sells',\n",
    "      'takes', 'uses', 'plans', 'looks', 'tends', 'hopes', 'argues', 'gives', 'pays', 'appears', 'suggests', 'fears',\n",
    "      'finds', 'comes', 'offers', 'contends', 'agrees', 'provides']\n",
    "\n",
    "attractor_helpers = ['in the', 'by the', 'close to the', 'of the', 'at the', 'and not the', 'without']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error_rate(sentences):\n",
    "    result = calculate_errors(sentences)\n",
    "    #print(result)\n",
    "    return 1- sum(result)/len(result)\n",
    "    \n",
    "def calculate_errors(sentences):\n",
    "    return [1 if is_correct_prediction(s[0], s[1], s[2]) else 0 for s in sentences]\n",
    "\n",
    "def is_correct_prediction(sentence, check_words, correct_word):\n",
    "    predictions = evaluate(lm, dictionary, sentence, check_words)\n",
    "    words,preds = zip(*list(map(lambda x: list(x.items())[0],predictions)))\n",
    "    predicted_word = words[np.argmax(preds)]\n",
    "    return predicted_word == correct_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compose sentence prefixes with frequent words with one and without attractors\n",
    "\n",
    "def gen_no_attractors(num_sentences, num_words, NN, NNS, VBP, VBZ):\n",
    "    assert(len(NN) == len(NNS) == len(VBP) == len(VBZ))\n",
    "    sentences_si = []\n",
    "    sentences_pl =[]\n",
    "    indices_x = []\n",
    "    indices_u = []\n",
    "    for i in range(num_sentences):\n",
    "        while True:\n",
    "            x,y = np.random.randint(num_words, size=2)\n",
    "            if (x,y) not in indices_x:\n",
    "                indices_x.append((x,y))\n",
    "                break\n",
    "        while True:\n",
    "            u,v = np.random.randint(num_words, size=2)\n",
    "            if (u,v) not in indices_u:\n",
    "                indices_u.append((u,v))\n",
    "                break\n",
    "        sentences_si.append((f\"the {NN[x]}\", [VBP[y], VBZ[y]], VBZ[y],))\n",
    "        sentences_pl.append((f\"the {NNS[u]}\", [VBP[v], VBZ[v]], VBP[v],))\n",
    "    return sentences_si, sentences_pl\n",
    "\n",
    "def gen_one_attractor(num_sentences, num_words, same, NN, NNS, VBP, VBZ, \n",
    "                      template = \"the {} of the {}\", first_dep = True):\n",
    "\n",
    "    assert(len(NN) == len(NNS) == len(VBP) == len(VBZ))\n",
    "    sentences_si = []\n",
    "    sentences_pl =[]\n",
    "    indices = []\n",
    "    for i in range(num_sentences):\n",
    "        while True:\n",
    "            x,y,z = np.random.randint(num_words, size=3)\n",
    "            if (x,y,z) not in indices:\n",
    "                indices.append((x,y,z))\n",
    "                break\n",
    "        if(same):\n",
    "            sentences_si.append((template.format(NN[x], NN[z]), [VBP[y], VBZ[y]], VBZ[y],))\n",
    "            sentences_pl.append((template.format(NNS[x], NNS[z]), [VBP[y], VBZ[y]], VBP[y],))\n",
    "        elif first_dep:\n",
    "            sentences_si.append((template.format(NN[x], NNS[z]), [VBP[y], VBZ[y]], VBZ[y],))\n",
    "            sentences_pl.append((template.format(NNS[x], NN[z]), [VBP[y], VBZ[y]], VBP[y],))\n",
    "        else:\n",
    "            sentences_si.append((template.format(NNS[x], NN[z]), [VBP[y], VBZ[y]], VBZ[y],))\n",
    "            sentences_pl.append((template.format(NN[x], NNS[z]), [VBP[y], VBZ[y]], VBP[y],))\n",
    "    return sentences_si, sentences_pl\n",
    "\n",
    "num_sentences = 1000\n",
    "num_words = len(NN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "templates = [\n",
    "    \"the {} in the {}\", # attractor\n",
    "    \"the {} by the {}\", # attractor\n",
    "    \"the {} of the {}\", # attractor\n",
    "    \"the {} near the {}\", # attractor\n",
    "    \"the {} at the {}\", # attractor\n",
    "    \"the {} without the {}\", # attractor\n",
    "    \"the {} the {}\", \n",
    "    \"the {} that the {}\",\n",
    "    \"the {} whether the {}\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the {} in the {}\n",
      "the {} by the {}\n",
      "the {} of the {}\n",
      "the {} near the {}\n",
      "the {} at the {}\n",
      "the {} without the {}\n",
      "the {} the {}\n",
      "the {} that the {}\n",
      "the {} whether the {}\n",
      "{'the {} in the {}': 0.5895, 'the {} by the {}': 0.687, 'the {} of the {}': 0.6125, 'the {} near the {}': 0.6275, 'the {} at the {}': 0.704, 'the {} without the {}': 0.6719999999999999, 'the {} the {}': 0.7815, 'the {} that the {}': 0.788, 'the {} whether the {}': 0.8520000000000001}\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 1000\n",
    "\n",
    "results = {}\n",
    "for t in templates:\n",
    "    np.random.seed(100) #generate from same verbs and nouns for each template\n",
    "    print (t)\n",
    "    si, pl = gen_one_attractor(\n",
    "        num_sentences, \n",
    "        num_words, \n",
    "        False, \n",
    "        NN, \n",
    "        NNS, \n",
    "        VBP, \n",
    "        VBZ, \n",
    "        template = t, \n",
    "        first_dep = True)\n",
    "    si_most_recent_noun_rate = calculate_error_rate(si)\n",
    "    pl_most_recent_noun_rate = calculate_error_rate(pl)\n",
    "    most_recent_noun_rate = 0.5*(pl_most_recent_noun_rate + si_most_recent_noun_rate)\n",
    "    results[t] = most_recent_noun_rate\n",
    "\n",
    "\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "conj_template = \"the {} and the {}\"\n",
    "\n",
    "np.random.seed(100) #generate from same verbs and nouns for each template\n",
    "\n",
    "si_conj, _ = gen_one_attractor(\n",
    "    num_sentences, \n",
    "    num_words, \n",
    "    True, \n",
    "    NN, \n",
    "    NNS, \n",
    "    VBP, \n",
    "    VBZ, \n",
    "    template = conj_template)\n",
    "\n",
    "si_conj_last_noun_rate = 1 - calculate_error_rate(si_conj) #error means plural prediction which is actually good \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_template = \"the {} 's {}\"\n",
    "plural_template = \"the {} ' {}\"\n",
    "possessive_template = f\"{singular_template} ({plural_template})\"\n",
    "\n",
    "np.random.seed(100) #generate from same verbs and nouns for each template\n",
    "\n",
    "si_possesive, _ = gen_one_attractor(\n",
    "    num_sentences, \n",
    "    num_words, \n",
    "    False, \n",
    "    NN, \n",
    "    NNS, \n",
    "    VBP, \n",
    "    VBZ, \n",
    "    template = singular_template, first_dep=True)\n",
    "\n",
    "np.random.seed(100) #generate from same verbs and nouns for each template\n",
    "\n",
    "_, pl_possesive = gen_one_attractor(\n",
    "    num_sentences, \n",
    "    num_words, \n",
    "    False, \n",
    "    NN, \n",
    "    NNS, \n",
    "    VBP, \n",
    "    VBZ, \n",
    "    template = plural_template, first_dep=True)\n",
    "\n",
    "si_possessive_success_rate = calculate_error_rate(si_possesive)\n",
    "pl_possessive_success_rate = calculate_error_rate(pl_possesive)\n",
    "possessive_last_noun_rate = 0.5*(si_possessive_success_rate + pl_possessive_success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEMCAYAAAA1VZrrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7Nc/wtZYGBQsiPFjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6749e37b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_templates = [conj_template] + templates + [possessive_template]\n",
    "template_names = [f\"T{i + 1}\" for i in range(0, len(all_templates))]\n",
    "last_noun_rates = [si_conj_last_noun_rate] + list(results.values()) + [possessive_last_noun_rate]\n",
    "y_pos = np.arange(len(all_templates))\n",
    "plt.bar(y_pos, last_noun_rates, align='center', color=['r', 'r', 'r', 'r', 'r', 'r', 'r', 'g', 'g', 'g', 'g'])\n",
    "plt.xticks(y_pos, template_names)\n",
    "plt.ylabel('Last Noun Preference Rate')\n",
    "plt.title('Templates')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the {} and the {}',\n",
       " 'the {} in the {}',\n",
       " 'the {} by the {}',\n",
       " 'the {} of the {}',\n",
       " 'the {} near the {}',\n",
       " 'the {} at the {}',\n",
       " 'the {} without the {}',\n",
       " 'the {} the {}',\n",
       " 'the {} that the {}',\n",
       " 'the {} whether the {}',\n",
       " \"the {} 's {} (the {} ' {})\"]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.774"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_possessive_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_possessive_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_template = \"the {} {}\"\n",
    "\n",
    "np.random.seed(100) #generate from same verbs and nouns for each template\n",
    "\n",
    "\n",
    "si_x, pl_x = gen_one_attractor(\n",
    "    num_sentences, \n",
    "    num_words, \n",
    "    False, \n",
    "    NN, \n",
    "    NNS, \n",
    "    VBP, \n",
    "    VBZ, \n",
    "    template = x_template, first_dep=True)\n",
    "\n",
    "pl_x_success_rate = calculate_error_rate(pl_x)\n",
    "si_x_success_rate = calculate_error_rate(si_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.633"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_x_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.712"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_x_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n",
      "0.59\n",
      "0.69\n",
      "0.61\n",
      "0.63\n",
      "0.70\n",
      "0.67\n",
      "0.78\n",
      "0.79\n",
      "0.85\n",
      "0.72\n"
     ]
    }
   ],
   "source": [
    "for r in last_noun_rates:\n",
    "    print (\"%.2f\" % r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
