{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do required imports\n",
    "import difflib\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(2834)\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib as matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = torch.load('model.pt', map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dictionary word --> id \n",
    "dictionary = pickle.load(open('dict', 'rb'))\n",
    "\n",
    "# set the maximum sequence length\n",
    "max_seq_len = 50\n",
    "\n",
    "# function to transform sentence into word id's and put them in a pytorch Variable\n",
    "# NB Assumes the sentence is already tokenised!\n",
    "def tokenise(sentence, dictionary):\n",
    "    words = sentence.split(' ')\n",
    "    l = len(words)\n",
    "    assert l <= max_seq_len, \"sentence too long\"\n",
    "    token = 0\n",
    "    ids = torch.LongTensor(l)\n",
    "\n",
    "    for word in words:\n",
    "        try:\n",
    "            ids[token] = dictionary.word2idx[word]\n",
    "        except KeyError:\n",
    "            print( word)\n",
    "            raw_input()\n",
    "            ids[token] = dictionary.word2idx['<unk>']\n",
    "        token += 1\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pytorch softmax function\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "def evaluate(model, dictionary, sentence, check_words):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    \n",
    "    # number of tokens (= output size)\n",
    "    ntokens = len(dictionary)\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    # tokenise the sentence, put in torch Variable\n",
    "    test_data = tokenise(sentence, dictionary)\n",
    "    input_data = Variable(test_data, volatile=True)\n",
    "\n",
    "    # run the model, compute probabilities by applying softmax\n",
    "    output, hidden = model(input_data, hidden)\n",
    "    output_flat = output.view(-1, ntokens)\n",
    "    logits = output[-1, :]\n",
    "    sm = softmax(logits).view(ntokens)\n",
    "    \n",
    "    # get probabilities of certain words by looking up their\n",
    "    # indices and print them\n",
    "    def get_prob(word):\n",
    "        return sm[dictionary.word2idx[word]].data[0]\n",
    "\n",
    "    #print (sentence, '\\n')\n",
    "    #print ('\\n'.join(\n",
    "    #        ['%s: %f' % (word, get_prob(word)) for word in check_words]\n",
    "    #        ) )\n",
    "    return  [{word : get_prob(word)} for word in check_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compose sentence prefixes with frequent words.\n",
    "# The sentence prefixes are intended to test intervening nouns.\n",
    "\n",
    "\n",
    "NN = ['company', 'year', 'market', 'share', 'stock', 'system', 'president', 'business', \n",
    "      'quarter', 'government', 'time', 'week', 'price', 'group', 'interest',\n",
    "      'industry', 'unit','month', 'rate', 'investment', 'state', 'producer', 'income', \n",
    "      'program', 'bank', 'part', 'plan', 'sale', 'issue', 'tax', 'way', 'loss', 'executive', 'day', 'bid', 'data', 'line','hour', 'plant', 'concern']\n",
    "\n",
    "NNS = ['companies', 'years', 'markets', 'shares', 'stocks', 'systems', 'presidents', \n",
    "       'businesses', 'quarters', 'governments', 'times', 'weeks', 'prices', 'groups', 'interests', 'industries', \n",
    "       'units', 'months', 'rates', 'investments', 'states', 'producers', 'incomes', 'programs', 'banks', 'parts', 'plans', \n",
    "      'sales', 'issues', 'taxes', 'ways', 'losses', 'executives', 'days', 'bids', 'data', 'lines', 'hours', 'plants', 'concerns',]\n",
    "\n",
    "VBP = ['are', 'have', 'do', 'say', 'think', 'want', 'expect', 'include', 'ask', \n",
    "       'make', 'need', 'know', 'see', 'get', 'seem', 'remain', 'continue', 'show', 'buy', \n",
    "       'feel', 'go', 'sell', 'take', 'use', 'plan', 'look', 'tend', 'hope', 'argue', 'give',\n",
    "       'pay', 'appear', 'suggest', 'fear', 'find', 'come', 'offer', 'contend', 'agree', 'provide']\n",
    "\n",
    "VBZ = ['is', 'has', 'does', 'says', 'thinks', 'wants', 'expects', 'includes', 'asks', 'makes',\n",
    "      'needs', 'knows', 'sees', 'gets', 'seems', 'remains', 'continues', 'shows', 'buys', 'feels', 'goes', 'sells',\n",
    "      'takes', 'uses', 'plans', 'looks', 'tends', 'hopes', 'argues', 'gives', 'pays', 'appears', 'suggests', 'fears',\n",
    "      'finds', 'comes', 'offers', 'contends', 'agrees', 'provides']\n",
    "\n",
    "attractor_helpers = ['in the', 'by the', 'close to the', 'of the', 'at the', 'and not the', 'without']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_error_rate(sentences):\n",
    "    result = calculate_errors(sentences)\n",
    "    #print(result)\n",
    "    return 1- sum(result)/len(result)\n",
    "    \n",
    "def calculate_errors(sentences):\n",
    "    return [calculate_error(s) for s in sentences]\n",
    "\n",
    "def calculate_error(sentence):\n",
    "    return 1 if is_correct_prediction(sentence[0], sentence[1], sentence[2]) else 0 \n",
    "\n",
    "def is_correct_prediction(sentence, check_words, correct_word):\n",
    "    predictions = evaluate(lm, dictionary, sentence, check_words)\n",
    "    words,preds = zip(*list(map(lambda x: list(x.items())[0],predictions)))\n",
    "    predicted_word = words[np.argmax(preds)]\n",
    "    return predicted_word == correct_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compose sentence prefixes with frequent words with one and without attractors\n",
    "\n",
    "def gen_simple_case_matrix(NN, NNS, VBP, VBZ):\n",
    "    assert(len(VBP) == len(VBZ))\n",
    "\n",
    "    nouns = NN + NNS\n",
    "    noun_count = len(nouns)\n",
    "    verb_count = len(VBP)\n",
    "    result = []\n",
    "    for index_noun in range(noun_count):\n",
    "        row = []\n",
    "        for index_verb in range(verb_count):\n",
    "            correct = VBZ[index_verb] if index_noun < len(NN) else VBP[index_verb]\n",
    "            sentence = (f\"the {nouns[index_noun]}\", [VBP[index_verb], VBZ[index_verb]], correct)\n",
    "            #row.append(sentence)\n",
    "            row.append(calculate_error(sentence))\n",
    "        result.append(row)\n",
    "    return result\n",
    "            \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple cases: nouns x verbs results, 0 = error, 1 = correct\n",
    "# first half of the rows are singular nouns,\n",
    "# second half are plural nouns\n",
    "n = 30 \n",
    "\n",
    "noun_verb_matrix = np.array(gen_simple_case_matrix(NN[0:n], NNS[0:n], VBP[0:n], VBZ[0:n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Todo sort columns and rows and make sense of it (by looking at frequencies)\n",
    "# split in NN and NNS\n",
    "matrix_NN = noun_verb_matrix[:n]\n",
    "matrix_NNS = np.array(noun_verb_matrix[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort after col\n",
    "matrix_NN_sorted_idx_col = np.argsort(matrix_NN.sum(axis=0))\n",
    "matrix_NN_sorted_col = matrix_NN[:, matrix_NN_sorted_idx_col]\n",
    "matrix_NNS_sorted_idx_col = np.argsort(matrix_NNS.sum(axis=0))\n",
    "matrix_NNS_sorted_col = matrix_NNS[:, matrix_NNS_sorted_idx_col]\n",
    "# sort after row\n",
    "matrix_NN_sorted_idx_row = np.argsort(matrix_NN_sorted_col.sum(axis=1))\n",
    "matrix_NN_sorted_row = matrix_NN_sorted_col[matrix_NN_sorted_idx_row,:]\n",
    "matrix_NNS_sorted_idx_row = np.argsort(-matrix_NNS_sorted_col.sum(axis=1))\n",
    "matrix_NNS_sorted_row = matrix_NNS_sorted_col[matrix_NNS_sorted_idx_row,:]\n",
    "#concatenate matrices\n",
    "matrix = np.concatenate((matrix_NN_sorted_row,matrix_NNS_sorted_row),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJQAAAD/CAYAAAAXD/9NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngbJUDpSlcqAslQNlqf4Hw/llZA9X/SMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1354f8668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(matrix.shape)\n",
    "plt.imshow(matrix, cmap=cm.gray)\n",
    "plt.show()\n",
    "plt.imsave('matrix_plot.png',matrix, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the sort order for the upper half of the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IDEA: \n",
    "# Color code verb plurality ratios, i.e. Count(produce)/Count(produces)\n",
    "# and print below diagram as some sort of 'x-axis'\n",
    "# Color code noun counts, i.e. Count(company)\n",
    "# and print at the left of the diagram as some sort of 'y-axis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IDEA: \n",
    "# Create the same diagram for the infrequent nouns. \n",
    "# Presumably they are more likely to follow verb preferences, can we see that in the shape?\n",
    "\n",
    "# Try also to sort the colomns using the column sorting indexes as in the figure above \n",
    "# (instead of using the sum criterion).\n",
    "# Presumably the verbs have the same preferences, can we see that in the shape?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IDEA:\n",
    "# The model outputs probabilities. Instead of just printing black and white it may be interested to\n",
    "# indicate the uncertainty of the model in grey teints\n",
    "# p-verb = p-plural + p-singular, colorcode = p-plural/p-verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
