\section{Introduction}

%%%%%%%%%%% Problem Area: RNN, LSTM networks
Neural networks have become increasingly popular
for the task of language modeling.
While feed-forward networks only take into account
a fixed history of preceeding words to predict the next word,
standard recurrent neural networks (RNN) and 
Long Short-Term Memory (LSTM) network architectures
have the ability to capture long-distance statistical regularities.
The access to potentially unlimited history 
has resulted in substantial improvements 
in perplexity and error rates
compared to feed-forward networks~\cite{Mikolov2010,Sundermeyer2013}. 

%%%%%%%%%%% Context: What do we already know
Regularities in natural language are often sensitive to syntactic structure.
RNNs and LSTMs are sequence models that do not explicitly
incorporate syntactic structure,
capturing such dependencies is therefore challenging.
Linzen et al.~\ref{Linzen2016} investigate the capability
of LSTMs to learn syntactic dependencies, taking
number agreement in noun-verb dependencies as an example.
%They compare the performance of
%a general LSTM language model with the performance of 
%LSTM models trained on explicit grammatical targets.
%They conclude that LSTMs can capture 
%structure-sensitive dependencies given explicit supervision;
%while the language modeling objective is not sufficient for learning
%such dependencies.
Their results show that the language modeling objective by itself
is not sufficient for learning structure-sensitive dependencies;
and that more explicit supervision is required.

%%%%%%%%%%% Problem + Approach
In this paper we investigate an LSTM language model
in more detail to get a better insight into what 
information these models actually encode.
We consider statistic, syntactic and semantic information
and analyse how the model uses this information
to establish number agreement. 
We take an empirical approach.
That is, we treat the model as a black box
and learn about it by observing its behavior
in carefully designed experiments.

%%%%%%%%%%% Results
The results show that ...

%\paragraph{Outline}
%The remainder of this report is organized as follows \ldots

%We first repeat the experiments from the linzen paper
%on a language model trained on PTB corpus.
%We reach similar conclusions,
%TODO: what about distance?
%While the model can establish number agreement
%for simple cases without intervening nouns,
%it fails for more complex cases scoring below average.

%We then take a closer look on the errors
%it made on simple cases without intervening nouns.
%By analyzing noun/verb combinations
%we identify verbs that show a strong preference for either
%one of the forms (singlar or plural),
%ignoring the count of the noun.
%In addition, we identified nouns that
%the model seems to have failed to learn or even mis-learned
%the number.
%We explained these cases by frequency statistics on the training corpus.

%We then look at syntactic information exposed 
%by function words such as 'that' and 'of'.
%We measure the performance of the model on 
%generated sentences constructed following a specific
%syntactic structure. 
%From this experiment we learned that
%function words can help the model to establish
%number agreement with the structurally relevant noun.
%But the evidence is very week.

%Thus far we looked at random generated nonsense
%sentences, ignoring the fact that sentences 
%are typically about something.
%In real world sentences some verbs 
%tend to form subject verb dependencies with certain nouns
%while other nouns do not mae sense.
%This can help the model.
%The price of the products stabilize/stabilizes.
%prices are semanticly related to stabilize,
%while products are not.
%We compare prefixes with a noun that
%is semantically related 
%compare with same prefic with noun replaced by random noun.
%to prefixes with a noun that is not.
%Does the semantic relation helps to establish
%number agreement with the relevant noun?

%From these experiments we conclude that
%...
