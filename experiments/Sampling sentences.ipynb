{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_verb_prefixes(sentences):\n",
    "    for s in sentences:\n",
    "        tokens = s.split(\" \")\n",
    "        for i, t in enumerate(tokens):\n",
    "            if re.search(\"VBZ|VBP\", t):\n",
    "                yield \" \".join(tokens[0:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relevant tags:\n",
    "# NN: toy\n",
    "# NNS: toys\n",
    "# NNP: IBM\n",
    "# NNPS: Carolinas\n",
    "# PRP: I, you, he\n",
    "# VBP: eat\n",
    "# VBZ: eats\n",
    "\n",
    "# constraint: all words should occur in training corpus [or we remove words that are not in the corpus?]\n",
    "# constraint: VBP => exactly one NNS (or NNPS, or plural PRP)\n",
    "# constraint: VBZ => exactly one NN (or NNP, or singular PRP)\n",
    "\n",
    "# example 1\n",
    "#plurality: VBP\n",
    "#attractors: 1 (number of intervening nons of opposite number)\n",
    "#distance: 3 (number of words between subject and verb)\n",
    "\n",
    "def analyze_sentences(sentences):\n",
    "    for s in sentences:\n",
    "        pos_regex = r\"\\|([A-Z]+)(?= |$)\"\n",
    "        tag_sequence = re.findall(pos_regex, s)\n",
    "        if tag_sequence.count(\"NNPS\") or tag_sequence.count(\"NNP\") or tag_sequence.count(\"PRP\") or tag_sequence.count(\"EX\"): \n",
    "            #print(s)\n",
    "            continue # for now: ignore sentences with \"NNPS, NNP, PRP, EX \n",
    "        plurality = tag_sequence[-1]\n",
    "        (nn_same, nn_opposite) = (\"NNS\", \"NN\") if plurality == \"VBP\" else (\"NN\", \"NNS\")\n",
    "        if not(tag_sequence.count(nn_same) == 1): \n",
    "            #print(s)\n",
    "            continue #constraint: ensure exactly one potential subject\n",
    "        subject_index = tag_sequence.index(nn_same) \n",
    "        distance = len(tag_sequence) - subject_index - 2\n",
    "        nr_of_attractors = tag_sequence[subject_index:].count(nn_opposite) \n",
    "        yield (s, plurality, distance, nr_of_attractors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(s, plurality, distance, nr_of_attractors)\n",
    "\n",
    "def categorize_by_prop(sentence_tuples, prop_index):\n",
    "    propdict = defaultdict(list)\n",
    "    for t in sentence_tuples:\n",
    "        prop = t[prop_index]\n",
    "        propdict[prop] = propdict[prop] + [t]\n",
    "    return propdict\n",
    "\n",
    "def categorize_by_plurality(sentence_tuples):\n",
    "    return categorize_by_prop(sentence_tuples, 1)\n",
    "\n",
    "def categorize_by_distance(sentence_tuples):\n",
    "    return categorize_by_prop(sentence_tuples, 2)\n",
    "\n",
    "def categorize_by_attractor_count(sentence_tuples):\n",
    "    return categorize_by_prop(sentence_tuples, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"sec02-21.gold.tagged\", \"r\") \n",
    "content = file.read()\n",
    "sentences = content.split(\".|.\")\n",
    "verb_prefixes = list(get_verb_prefixes(sentences))\n",
    "analyzed_prefixes = list(analyze_sentences(verb_prefixes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attractor_stats = categorize_by_attractor_count(analyzed_prefixes) # sentences with various number of attractors (momogeneous) \n",
    "distance_stats = categorize_by_distance(attractor_stats[0]) # sentences without attractors but varying distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' \\nThat|DT burden|NN is|VBZ very|RB difficult|JJ ,|, if|IN not|RB impossible|JJ ,|, to|TO meet|VB ,|, says|VBZ',\n",
       "  'VBZ',\n",
       "  8,\n",
       "  0),\n",
       " (' \\nWhat|WP far|RB too|RB many|JJ people|NNS concerned|JJ about|IN education|NN either|CC fail|VB to|TO understand|VB or|CC choose|VB to|TO ignore|VB is|VBZ',\n",
       "  'VBZ',\n",
       "  8,\n",
       "  0),\n",
       " (' \\nThe|DT opposition|NN can|MD be|VB the|DT most|RBS hurt|VBN because|IN everyone|DT already|RB figures|VBZ',\n",
       "  'VBZ',\n",
       "  8,\n",
       "  0),\n",
       " (\" \\nSell|VB stocks|NNS that|WDT are|VBP n't|RB doing|VBG well|RB now|RB ,|, and|CC that|DT do|VBP\",\n",
       "  'VBP',\n",
       "  8,\n",
       "  0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_stats[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 426 nsubj [I]\n",
      "I\n",
      "thought 8206900633647566924 ROOT [I, thought, it, was, the, complete, set]\n",
      "it 426 nsubj [it]\n",
      "it\n",
      "was 405 ccomp [it, was, the, complete, set]\n",
      "the 412 det [the]\n",
      "complete 399 amod [complete]\n",
      "set 401 attr [the, complete, set]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "parsed_text = nlp(u\"I thought it was the complete set\")\n",
    "\n",
    "#get token dependencies\n",
    "for text in parsed_text:\n",
    "    print (text, text.dep, text.dep_, list(text.subtree))\n",
    "    if text.dep_ == \"nsubj\":\n",
    "        subject = text.orth_\n",
    "        print(subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NE': '',\n",
       "  'POS_coarse': 'VERB',\n",
       "  'POS_fine': 'VBD',\n",
       "  'arc': 'ROOT',\n",
       "  'lemma': 'think',\n",
       "  'modifiers': [{'NE': '',\n",
       "    'POS_coarse': 'PRON',\n",
       "    'POS_fine': 'PRP',\n",
       "    'arc': 'nsubj',\n",
       "    'lemma': '-PRON-',\n",
       "    'modifiers': [],\n",
       "    'word': 'I'},\n",
       "   {'NE': '',\n",
       "    'POS_coarse': 'VERB',\n",
       "    'POS_fine': 'VBD',\n",
       "    'arc': 'ccomp',\n",
       "    'lemma': 'be',\n",
       "    'modifiers': [{'NE': '',\n",
       "      'POS_coarse': 'PRON',\n",
       "      'POS_fine': 'PRP',\n",
       "      'arc': 'nsubj',\n",
       "      'lemma': '-PRON-',\n",
       "      'modifiers': [],\n",
       "      'word': 'it'},\n",
       "     {'NE': '',\n",
       "      'POS_coarse': 'NOUN',\n",
       "      'POS_fine': 'NN',\n",
       "      'arc': 'attr',\n",
       "      'lemma': 'set',\n",
       "      'modifiers': [{'NE': '',\n",
       "        'POS_coarse': 'DET',\n",
       "        'POS_fine': 'DT',\n",
       "        'arc': 'det',\n",
       "        'lemma': 'the',\n",
       "        'modifiers': [],\n",
       "        'word': 'the'},\n",
       "       {'NE': '',\n",
       "        'POS_coarse': 'ADJ',\n",
       "        'POS_fine': 'JJ',\n",
       "        'arc': 'amod',\n",
       "        'lemma': 'complete',\n",
       "        'modifiers': [],\n",
       "        'word': 'complete'}],\n",
       "      'word': 'set'}],\n",
       "    'word': 'was'}],\n",
       "  'word': 'thought'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_text.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
