{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Grammar in Neural language models\n",
    "\n",
    "We will investigate a language model trained on the penn treebank dataset, using the code provided at https://github.com/pytorch/examples/tree/master/word_language_model. The model consists of an encoder with 2 hidden LSTM layers with 1500 units, and a linear output layer to which a softmax function is applied. The word embeddings have dimensionality 1500. The model is trained for 40 epochs with a dropout factor of 0.65 and has a test perplexity of 72.30 on the test set. If you are interested in more detail in the model, we advise you to look at the repository containing the code.\n",
    "\n",
    "In this notebook, we will walk you through an example of how you can compute the probabilties of the next word in a sentence. You can then use this to start your replication of Linzen et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do required imports\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(2834)\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib as matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you downloaded and extracted the zipfile, you should have all data required: the model, and the pickled dictionary mapping words to indices.\n",
    "\n",
    "Lets start by loading the model. Because the model was trained on a GPU, we need to specifically say that it should be loaded on the CPU when we load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = torch.load('model.pt', map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel (\n",
      "  (drop): Dropout (p = 0.65)\n",
      "  (encoder): Embedding(10000, 1500)\n",
      "  (rnn): LSTM(1500, 1500, num_layers=2, dropout=0.65)\n",
      "  (decoder): Linear (1500 -> 10000)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print a summary of the architecture of your model\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a single sentence\n",
    "\n",
    "We will give an example of how you can get the probabilties for the next word in a single sentence. We will uset he example sentence:<br>\n",
    "\n",
    "\"This is a sentence with seven\"\n",
    "\n",
    "And print the probabilities of completing this sentence with either 'words', 'characters', 'thursday', 'days' or 'walk'. As the model itself does not include the mapping from words to indices, we will need to do this as a preprocessing step. The dictionary that maps words to indices is stored in a pickled file called 'dict'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dictionary word --> id \n",
    "dictionary = pickle.load(open('dict', 'rb'))\n",
    "\n",
    "# set the maximum sequence length\n",
    "max_seq_len = 50\n",
    "\n",
    "# function to transform sentence into word id's and put them in a pytorch Variable\n",
    "# NB Assumes the sentence is already tokenised!\n",
    "def tokenise(sentence, dictionary):\n",
    "    words = sentence.split(' ')\n",
    "    l = len(words)\n",
    "    assert l <= max_seq_len, \"sentence too long\"\n",
    "    token = 0\n",
    "    ids = torch.LongTensor(l)\n",
    "\n",
    "    for word in words:\n",
    "        try:\n",
    "            ids[token] = dictionary.word2idx[word]\n",
    "        except KeyError:\n",
    "            print( word)\n",
    "            raw_input()\n",
    "            ids[token] = dictionary.word2idx['<unk>']\n",
    "        token += 1\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that can be used to evaluate a single sentence and print the probabilities of finishing this sentence with a word from a list of input words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pytorch softmax function\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "def evaluate(model, dictionary, sentence, check_words):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    \n",
    "    # number of tokens (= output size)\n",
    "    ntokens = len(dictionary)\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    # tokenise the sentence, put in torch Variable\n",
    "    test_data = tokenise(sentence, dictionary)\n",
    "    input_data = Variable(test_data, volatile=True)\n",
    "\n",
    "    # run the model, compute probabilities by applying softmax\n",
    "    output, hidden = model(input_data, hidden)\n",
    "    output_flat = output.view(-1, ntokens)\n",
    "    logits = output[-1, :]\n",
    "    sm = softmax(logits).view(ntokens)\n",
    "    \n",
    "    # get probabilities of certain words by looking up their\n",
    "    # indices and print them\n",
    "    def get_prob(word):\n",
    "        return sm[dictionary.word2idx[word]].data[0]\n",
    "\n",
    "    #print (sentence, '\\n')\n",
    "    #print ('\\n'.join(\n",
    "    #        ['%s: %f' % (word, get_prob(word)) for word in check_words]\n",
    "    #        ) )\n",
    "\n",
    "    return {word : get_prob(word) for word in check_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test sentence and words to check\n",
    "test_sentence = 'this is a sentence with seven'\n",
    "check_words = ['words', 'characters', 'thursday', 'days', 'walk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'characters': 7.000279583735391e-05,\n",
       " 'days': 0.002636461518704891,\n",
       " 'thursday': 1.165580556516943e-06,\n",
       " 'walk': 5.386583779909415e-06,\n",
       " 'words': 0.0009886504849418998}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lm, dictionary, test_sentence, check_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now try it yourself\n",
    "\n",
    "You can now start with your replication of Linzen's paper, for which the first step is to try different inputs with varying distances etc. to get a feeling for what the model is doing and to familiarise yourself with using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'are': 0.031047170981764793, 'is': 0.00332761462777853}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"the toy on the tables\"\n",
    "check_words = [\"is\", \"are\"]\n",
    "evaluate(lm, dictionary, test_sentence, check_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sentence, options, correct-option):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the product of the company', ['looks', 'look'], 'looks'),\n",
       " ('the products of the company', ['looks', 'look'], 'look'),\n",
       " ('the product of the companies', ['looks', 'look'], 'looks'),\n",
       " ('the products of the companies', ['looks', 'look'], 'look'),\n",
       " ('the product that the company', ['produces', 'produce'], 'produces'),\n",
       " ('the products that the company', ['produces', 'produce'], 'produces'),\n",
       " ('the product that the companies', ['produces', 'produce'], 'produce'),\n",
       " ('the products that the companies', ['produces', 'produce'], 'produce'),\n",
       " ('the product that the company produces', ['looks', 'look'], 'looks'),\n",
       " ('the products that the company produces', ['looks', 'look'], 'look'),\n",
       " ('the product that the companies produce', ['looks', 'look'], 'looks'),\n",
       " ('the products that the companies produce', ['looks', 'look'], 'look')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compose sentence prefixes with frequent words.\n",
    "# The sentence prefixes are intended to test intervening nouns.\n",
    "\n",
    "\n",
    "NN = ['company', 'year', 'market', 'share', 'stock', 'system', 'president', 'business', \n",
    "      'quarter', 'government', 'time', 'week', 'price', 'group', 'interest',\n",
    "      'industry', 'unit','month', 'rate', 'investment', 'state', 'producer', 'income', \n",
    "      'program', 'bank', 'part', 'plan', 'sale', 'issue', 'tax', 'way', 'loss', 'executive', 'day', 'bid', 'data', 'line','hour', 'plant', 'concern']\n",
    "\n",
    "NNS = ['companies', 'years', 'markets', 'shares', 'stocks', 'systems', 'presidents', \n",
    "       'businesses', 'quarters', 'governments', 'times', 'weeks', 'prices', 'groups', 'interests', 'industries', \n",
    "       'units', 'months', 'rates', 'investments', 'states', 'producers', 'incomes', 'programs', 'banks', 'parts', 'plans', \n",
    "      'sales', 'issues', 'taxes', 'ways', 'losses', 'executives', 'days', 'bids', 'data', 'lines', 'hours', 'plants', 'concerns',]\n",
    "\n",
    "VBP = ['are', 'have', 'do', 'say', 'think', 'want', 'expect', 'include', 'ask', \n",
    "       'make', 'need', 'know', 'see', 'get', 'seem', 'remain', 'continue', 'show', 'buy', \n",
    "       'feel', 'go', 'sell', 'take', 'use', 'plan', 'look', 'tend', 'hope', 'argue', 'give',\n",
    "       'pay', 'appear', 'suggest', 'fear', 'find', 'come', 'offer', 'contend', 'agree', 'provide']\n",
    "\n",
    "VBZ = ['is', 'has', 'does', 'says', 'thinks', 'wants', 'expects', 'includes', 'asks', 'makes',\n",
    "      'needs', 'knows', 'sees', 'gets', 'seems', 'remains', 'continues', 'shows', 'buys', 'feels', 'goes', 'sells',\n",
    "      'takes', 'uses', 'plans', 'looks', 'tends', 'hopes', 'argues', 'gives', 'pays', 'appears', 'suggests', 'fears',\n",
    "      'finds', 'comes', 'offers', 'contends', 'agrees', 'provides']\n",
    "\n",
    "attractor_helpers = ['in the', 'by the', 'close to the', 'of the', 'at the', 'and not the', 'without']\n",
    "\n",
    "words = {\n",
    "    \"NN1\" : \"product\",\n",
    "    \"NNS1\" : \"products\",\n",
    "    \"NN2\" : \"company\",\n",
    "    \"NNS2\" : \"companies\",\n",
    "    \"VBP1\" : \"looks\",\n",
    "    \"VBZ1\" : \"look\",\n",
    "    \"VBP2\" : \"produces\",\n",
    "    \"VBZ2\" : \"produce\",\n",
    "}\n",
    "sentences = [\n",
    "    (f\"the {words['NN1']} of the {words['NN2']}\", [words['VBP1'], words['VBZ1']], words['VBP1']),\n",
    "    (f\"the {words['NNS1']} of the {words['NN2']}\", [words['VBP1'], words['VBZ1']], words['VBZ1']),\n",
    "    (f\"the {words['NN1']} of the {words['NNS2']}\", [words['VBP1'], words['VBZ1']], words['VBP1']),\n",
    "    (f\"the {words['NNS1']} of the {words['NNS2']}\", [words['VBP1'], words['VBZ1']], words['VBZ1']),\n",
    "\n",
    "    (f\"the {words['NN1']} that the {words['NN2']}\", [words['VBP2'], words['VBZ2']], words['VBP2']),\n",
    "    (f\"the {words['NNS1']} that the {words['NN2']}\", [words['VBP2'], words['VBZ2']], words['VBP2']),\n",
    "    (f\"the {words['NN1']} that the {words['NNS2']}\", [words['VBP2'], words['VBZ2']], words['VBZ2']),\n",
    "    (f\"the {words['NNS1']} that the {words['NNS2']}\", [words['VBP2'], words['VBZ2']], words['VBZ2']),\n",
    "\n",
    "    (f\"the {words['NN1']} that the {words['NN2']} {words['VBP2']}\", [words['VBP1'], words['VBZ1']], words['VBP1']),\n",
    "    (f\"the {words['NNS1']} that the {words['NN2']} {words['VBP2']}\", [words['VBP1'], words['VBZ1']], words['VBZ1']),\n",
    "    (f\"the {words['NN1']} that the {words['NNS2']} {words['VBZ2']}\", [words['VBP1'], words['VBZ1']], words['VBP1']),\n",
    "    (f\"the {words['NNS1']} that the {words['NNS2']} {words['VBZ2']}\", [words['VBP1'], words['VBZ1']], words['VBZ1'])\n",
    "]\n",
    "\n",
    "print(\"(sentence, options, correct-option):\")\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_error_rate(sentences):\n",
    "    result = calculate_errors(sentences)\n",
    "    #print(result)\n",
    "    return 1- sum(result)/len(result)\n",
    "    \n",
    "def calculate_errors(sentences):\n",
    "    return [1 if is_correct_prediction(s[0], s[1], s[2]) else 0 for s in sentences]\n",
    "\n",
    "def is_correct_prediction(sentence, check_words, correct_word):\n",
    "    predictions = evaluate(lm, dictionary, sentence, check_words)\n",
    "    predicted_word = max(predictions, key=predictions.get)\n",
    "    return predicted_word == correct_word\n",
    "    \n",
    "calculate_error_rate(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compose sentence prefixes with frequent words with one and without attractors\n",
    "\n",
    "def gen_no_attractors(num_sentences, num_words, NN, NNS, VBP, VBZ):\n",
    "    assert(len(NN) == len(NNS) == len(VBP) == len(VBZ))\n",
    "    sentences_si = []\n",
    "    sentences_pl =[]\n",
    "    indices_x = []\n",
    "    indices_u = []\n",
    "    for i in range(num_sentences):\n",
    "        while True:\n",
    "            x,y = np.random.randint(num_words, size=2)\n",
    "            if (x,y) not in indices_x:\n",
    "                indices_x.append((x,y))\n",
    "                break\n",
    "        while True:\n",
    "            u,v = np.random.randint(num_words, size=2)\n",
    "            if (u,v) not in indices_u:\n",
    "                indices_u.append((u,v))\n",
    "                break\n",
    "        sentences_si.append((f\"the {NN[x]}\", [VBP[y], VBZ[y]], VBZ[y],))\n",
    "        sentences_pl.append((f\"the {NNS[u]}\", [VBP[v], VBZ[v]], VBP[v],))\n",
    "    return sentences_si, sentences_pl\n",
    "\n",
    "def gen_one_attractor(num_sentences, num_words, same, NN, NNS, VBP, VBZ, \n",
    "                      template = \"the {} of the {}\", first_dep = True):\n",
    "\n",
    "    assert(len(NN) == len(NNS) == len(VBP) == len(VBZ))\n",
    "    sentences_si = []\n",
    "    sentences_pl =[]\n",
    "    indices = []\n",
    "    for i in range(num_sentences):\n",
    "        while True:\n",
    "            x,y,z = np.random.randint(num_words, size=3)\n",
    "            if (x,y,z) not in indices:\n",
    "                indices.append((x,y,z))\n",
    "                break\n",
    "        if(same):\n",
    "            sentences_si.append((template.format(NN[x], NN[z]), [VBP[y], VBZ[y]], VBZ[y],))\n",
    "            sentences_pl.append((template.format(NNS[x], NNS[z]), [VBP[y], VBZ[y]], VBP[y],))\n",
    "        elif first_dep:\n",
    "            sentences_si.append((template.format(NN[x], NNS[z]), [VBP[y], VBZ[y]], VBZ[y],))\n",
    "            sentences_pl.append((template.format(NNS[x], NN[z]), [VBP[y], VBZ[y]], VBP[y],))\n",
    "        else:\n",
    "            sentences_si.append((template.format(NNS[x], NN[z]), [VBP[y], VBZ[y]], VBZ[y],))\n",
    "            sentences_pl.append((template.format(NN[x], NNS[z]), [VBP[y], VBZ[y]], VBP[y],))\n",
    "    return sentences_si, sentences_pl\n",
    "\n",
    "num_sentences = 1000\n",
    "num_words = len(NN)\n",
    "\n",
    "no_attractors_si, no_attractors_pl = gen_no_attractors(num_sentences, num_words, NN, NNS, VBP, VBZ)\n",
    "one_attractor_si_same, one_attractor_pl_same = gen_one_attractor(num_sentences, num_words,True, NN, NNS, VBP, VBZ)\n",
    "one_attractor_si_diff, one_attractor_pl_diff = gen_one_attractor(num_sentences, num_words,False, NN, NNS, VBP, VBZ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the sale', ['tend', 'tends'], 'tends'), ('the income', ['sell', 'sells'], 'sells')]\n",
      "[('the incomes', ['sell', 'sells'], 'sell'), ('the data', ['go', 'goes'], 'go')]\n",
      "[('the unit of the part', ['think', 'thinks'], 'thinks'), ('the hour of the president', ['give', 'gives'], 'gives')]\n",
      "[('the units of the parts', ['think', 'thinks'], 'think'), ('the hours of the presidents', ['give', 'gives'], 'give')]\n",
      "[('the state of the companies', ['hope', 'hopes'], 'hopes'), ('the business of the markets', ['provide', 'provides'], 'provides')]\n",
      "[('the states of the company', ['hope', 'hopes'], 'hope'), ('the businesses of the market', ['provide', 'provides'], 'provide')]\n"
     ]
    }
   ],
   "source": [
    "print(no_attractors_si[0:2])\n",
    "print(no_attractors_pl[0:2])\n",
    "print(one_attractor_si_same[0:2])\n",
    "print(one_attractor_pl_same[0:2])\n",
    "print(one_attractor_si_diff[0:2])\n",
    "print(one_attractor_pl_diff[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# caluclate error for 2b\n",
    "err_no_attractors_si = calculate_error_rate(no_attractors_si)\n",
    "err_no_attractors_pl = calculate_error_rate(no_attractors_pl)\n",
    "err_one_attractor_si_same =  calculate_error_rate(one_attractor_si_same)\n",
    "err_one_attractor_pl_same = calculate_error_rate(one_attractor_pl_same)\n",
    "err_one_attractor_si_diff = calculate_error_rate(one_attractor_si_diff)\n",
    "err_one_attractor_pl_diff = calculate_error_rate(one_attractor_pl_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEACAYAAAB27puMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1416adb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reproduce plot from the paper 2b\n",
    "N = 2\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.1       # the width of the bars\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "yvals = [err_no_attractors_pl, err_no_attractors_si]\n",
    "rects1 = ax.bar(ind, yvals, width, color='b')\n",
    "zvals = [err_one_attractor_pl_same, err_one_attractor_si_diff]\n",
    "rects2 = ax.bar(ind+width, zvals, width, color='g')\n",
    "kvals = [err_one_attractor_pl_diff, err_one_attractor_si_same ]\n",
    "rects3 = ax.bar(ind+width*2, kvals, width, color='r')\n",
    "\n",
    "ax.set_ylabel('Error rate')\n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels( ('Plural subject', 'Singular subject') )\n",
    "ax.set_ylim([0,0.7])\n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('None', 'Plural', 'Singular'),title='Last intervening noun')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('2b.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error plural subject: (None, Plural, Singular)\n",
      "(0.17700000000000005, 0.18600000000000005, 0.579)\n",
      "Erro singular subject: (None, Plural, Singular)\n",
      "(0.15200000000000002, 0.608, 0.15100000000000002)\n"
     ]
    }
   ],
   "source": [
    "print(\"Error plural subject: (None, Plural, Singular)\")\n",
    "print((err_no_attractors_pl, err_one_attractor_pl_same,err_one_attractor_pl_diff))\n",
    "print(\"Erro singular subject: (None, Plural, Singular)\")\n",
    "print((err_no_attractors_si,err_one_attractor_si_diff,err_one_attractor_si_same))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose sentence prefixes with frequent words with 0-4 attractors \n",
    "def gen_num_attractors(num_sentences, num_words, num_attractors, NN, NNS, VBP, VBZ, helper):\n",
    "    assert(num_attractors >= 0)\n",
    "    assert(len(NN) == len(NNS) == len(VBP) == len(VBZ))\n",
    "    sentences = []\n",
    "    store_indices = []\n",
    "    for i in range(num_sentences):\n",
    "        x = np.random.randint(2, size=1)\n",
    "        while True:\n",
    "            indices = np.random.randint(num_words, size=2+num_attractors+1)\n",
    "            if tuple(indices) not in store_indices:\n",
    "                store_indices.append(tuple(indices))\n",
    "                break\n",
    "#  homogeneous interventions (only consists of agreement attractors)\n",
    "\n",
    "        if(x == 0):\n",
    "            sent = f\"the {NN[indices[0]]}\"\n",
    "        else:\n",
    "            sent = f\"the {NNS[indices[0]]}\"\n",
    "        for j in range(1,num_attractors+1):\n",
    "            index = np.random.randint(len(helper), size=1)[0]\n",
    "            if(x == 0):\n",
    "                sent += f\" {helper[index]} {NNS[indices[j]]}\"\n",
    "            else:\n",
    "                sent += f\" {helper[index]} {NN[indices[j]]}\"\n",
    "        if(x == 0):\n",
    "            sentences.append((sent, [VBP[indices[-1]], VBZ[indices[-1]]], VBZ[indices[-1]]))\n",
    "        else:\n",
    "            sentences.append((sent, [VBP[indices[-1]], VBZ[indices[-1]]], VBP[indices[-1]]))\n",
    "\n",
    "    return sentences\n",
    "\n",
    "no_attr = gen_num_attractors(num_sentences, num_words, 0, NN, NNS, VBP, VBZ, attractor_helpers)\n",
    "one_attr = gen_num_attractors(num_sentences, num_words, 1, NN, NNS, VBP, VBZ, attractor_helpers)\n",
    "two_attr = gen_num_attractors(num_sentences, num_words, 2, NN, NNS, VBP, VBZ, attractor_helpers)\n",
    "three_attr = gen_num_attractors(num_sentences, num_words, 3, NN, NNS, VBP, VBZ, attractor_helpers)\n",
    "four_attr = gen_num_attractors(num_sentences, num_words, 4, NN, NNS, VBP, VBZ, attractor_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caluclate error for 2c for singular and plural subjects\n",
    "err_no_attr = calculate_error_rate(no_attr)\n",
    "err_one_attr = calculate_error_rate(one_attr)\n",
    "err_two_attr = calculate_error_rate(two_attr)\n",
    "err_three_attr = calculate_error_rate(three_attr)\n",
    "err_four_attr = calculate_error_rate(four_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for number of attractors: (0, 1, 2, 3, 4) \n",
      "(0.20899999999999996, 0.6699999999999999, 0.716, 0.716, 0.736)\n"
     ]
    }
   ],
   "source": [
    "print(\"Error for number of attractors: (0, 1, 2, 3, 4) \")\n",
    "print((err_no_attr, err_one_attr, err_two_attr, err_three_attr, err_four_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAERCAYAAAC+ZEqyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1318fc240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot error for 2c for singular and plural subjects: 2c_not_mixed.pdf\n",
    "err = [err_no_attr, err_one_attr,err_two_attr,err_three_attr,err_four_attr]\n",
    "\n",
    "x = np.arange(0,5) \n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_ylabel('Error rate')\n",
    "\n",
    "ax1.set_xlabel('Count of attractors')\n",
    "ax1.plot(x, err, color='g', linewidth=3)\n",
    "ax1.scatter(x,err,color='g',linewidth=4)\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax1.xaxis.set_major_locator(mtick.MaxNLocator(integer=True))\n",
    "ax1.set_ylim([0,0.8])\n",
    "ax1.legend(loc=2)\n",
    "plt.show()\n",
    "fig.savefig('2c.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the taxes', ['seem', 'seems'], 'seem'), ('the programs', ['want', 'wants'], 'want'), ('the data', ['hope', 'hopes'], 'hope'), ('the markets', ['ask', 'asks'], 'ask')]\n",
      "\n",
      "[('the days at the bank', ['give', 'gives'], 'give'), ('the shares without hour', ['sell', 'sells'], 'sell'), ('the group by the systems', ['have', 'has'], 'has'), ('the interests at the issue', ['want', 'wants'], 'want')]\n",
      "\n",
      "[('the government at the taxes and not the parts', ['have', 'has'], 'has'), ('the banks by the group of the unit', ['continue', 'continues'], 'continue'), ('the units of the bid close to the day', ['continue', 'continues'], 'continue'), ('the incomes and not the unit in the income', ['find', 'finds'], 'find')]\n",
      "\n",
      "[('the plan in the bids close to the rates by the months', ['see', 'sees'], 'sees'), ('the months and not the executive in the business at the concern', ['plan', 'plans'], 'plan'), ('the way close to the businesses by the groups close to the years', ['hope', 'hopes'], 'hopes'), ('the price by the bids at the years close to the stocks', ['do', 'does'], 'does')]\n",
      "\n",
      "[('the months in the issue and not the rate in the loss close to the unit', ['see', 'sees'], 'see'), ('the rate by the years and not the banks of the plans by the interests', ['see', 'sees'], 'sees'), ('the rate of the industries without data of the units by the times', ['tend', 'tends'], 'tends'), ('the share and not the lines and not the interests by the sales at the ways', ['appear', 'appears'], 'appears')]\n"
     ]
    }
   ],
   "source": [
    "# print sentences that incorporate 0-4 homogenous interventions\n",
    "print(no_attr[0:4])\n",
    "print()\n",
    "print(one_attr[0:4])\n",
    "print()\n",
    "print(two_attr[0:4])\n",
    "print()\n",
    "print(three_attr[0:4])\n",
    "print()\n",
    "print(four_attr[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rates different categories: \n",
      "0.62 example: ('the quarter of the shares', ['plan', 'plans'], 'plans')\n",
      "0.65 example: ('the quarters of the share', ['plan', 'plans'], 'plan')\n",
      "0.20 example: ('the quarters that the share', ['plan', 'plans'], 'plans')\n",
      "0.29 example: ('the quarter that the shares', ['plan', 'plans'], 'plan')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fd71a205c0d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merror_rate_one_attractor_pl_diff_relativizer\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34mf\"example: {one_attractor_pl_diff_relativizer[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0merror_rate_one_attractor_si_diff_no_relativizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_error_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_attractor_si_diff_no_relativizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merror_rate_one_attractor_si_diff_no_relativizer\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34mf\"example: {one_attractor_si_diff_no_relativizer[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-fedb29c0688a>\u001b[0m in \u001b[0;36mcalculate_error_rate\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_error_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-fedb29c0688a>\u001b[0m in \u001b[0;36mcalculate_errors\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_correct_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_correct_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-fedb29c0688a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_correct_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_correct_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-fedb29c0688a>\u001b[0m in \u001b[0;36mis_correct_prediction\u001b[0;34m(sentence, check_words, correct_word)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_correct_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mpredicted_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted_word\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcorrect_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f32d2dd4d7eb>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, dictionary, sentence, check_words)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# run the model, compute probabilities by applying softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0moutput_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Artificial Intelligence/Natural Language Processing/nlp1/experiments/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# These seed lines make sure that all test variations run on a testset\n",
    "# containing sentences that are composed from the same 'noun'-'verb' combinations.\n",
    "# This has two advantages:\n",
    "# 1) The error rates are more comparable\n",
    "# 2) The outputs can be compared on a one-by-one basis, i.e.\n",
    "# The <keys> that the <cabinet> ...[contain, contains]: 0, \n",
    "# The <keys>      the <cabinet> ...[contain, contains]: 1, \n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "#compare different templates\n",
    "#calculate_errors(one_attractor_si_same[0:100])\n",
    "one_attractor_si_diff_possesive, one_attractor_pl_diff_possesive = gen_one_attractor(\n",
    "    num_sentences, num_words,False, NN, NNS, VBP, VBZ, template = \"the {} of the {}\", first_dep = True)\n",
    "\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "#compare different templates\n",
    "#calculate_errors(one_attractor_si_same[0:100])\n",
    "one_attractor_si_diff_relativizer, one_attractor_pl_diff_relativizer = gen_one_attractor(\n",
    "    num_sentences, num_words,False, NN, NNS, VBP, VBZ, template = \"the {} that the {}\", first_dep = False)\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "one_attractor_si_diff_no_relativizer, one_attractor_pl_diff_no_relativizer = gen_one_attractor(\n",
    "    num_sentences, num_words,False, NN, NNS, VBP, VBZ, \"the {} the {}\", first_dep = False)\n",
    "\n",
    "print(\"Error rates different categories: \")\n",
    "\n",
    "error_rate_one_attractor_si_diff_possesive = calculate_error_rate(one_attractor_si_diff_possesive[0:100])\n",
    "print (\"%.2f\" % error_rate_one_attractor_si_diff_possesive , f\"example: {one_attractor_si_diff_possesive[0]}\")\n",
    "\n",
    "error_rate_one_attractor_pl_diff_possesive = calculate_error_rate(one_attractor_pl_diff_possesive[0:100])\n",
    "print (\"%.2f\" % error_rate_one_attractor_pl_diff_possesive , f\"example: {one_attractor_pl_diff_possesive[0]}\")\n",
    "\n",
    "error_rate_one_attractor_si_diff_relativizer = calculate_error_rate(one_attractor_si_diff_relativizer[0:100])\n",
    "print (\"%.2f\" % error_rate_one_attractor_si_diff_relativizer , f\"example: {one_attractor_si_diff_relativizer[0]}\")\n",
    "\n",
    "error_rate_one_attractor_pl_diff_relativizer = calculate_error_rate(one_attractor_pl_diff_relativizer[0:100])\n",
    "print (\"%.2f\" % error_rate_one_attractor_pl_diff_relativizer , f\"example: {one_attractor_pl_diff_relativizer[0]}\")\n",
    "\n",
    "error_rate_one_attractor_si_diff_no_relativizer = calculate_error_rate(one_attractor_si_diff_no_relativizer[0:100])\n",
    "print (\"%.2f\" % error_rate_one_attractor_si_diff_no_relativizer , f\"example: {one_attractor_si_diff_no_relativizer[0]}\")\n",
    "\n",
    "error_rate_one_attractor_pl_diff_no_relativizer = calculate_error_rate(one_attractor_pl_diff_no_relativizer[0:100])\n",
    "print (\"%.2f\" % error_rate_one_attractor_pl_diff_no_relativizer , f\"example: {one_attractor_pl_diff_no_relativizer[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
